# Equipment CBM MVP - è¨­å‚™çŠ¶æ…‹æ¨ç§»äºˆæ¸¬ã¨ä¿å…¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å¼·åŒ–å­¦ç¿’

## æ¦‚è¦

æ©Ÿæ¢°è¨­å‚™ã®æ¸©åº¦æ¸¬å®šãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ãŸçŠ¶æ…‹åŸºæº–ä¿å…¨(CBM)ã®å¼·åŒ–å­¦ç¿’MVPã§ã™ã€‚

**ç‰¹å¾´:**
- 2x2ãƒãƒ«ã‚³ãƒ•çŠ¶æ…‹é·ç§»ãƒ¢ãƒ‡ãƒ«ï¼ˆNormal / Anomalousï¼‰
- QR-DQNï¼ˆQuantile Regression DQNï¼‰ã«ã‚ˆã‚‹åˆ†å¸ƒå‹å¼·åŒ–å­¦ç¿’
- ãƒªã‚¹ã‚¯æŠ‘åˆ¶ã¨ã‚³ã‚¹ãƒˆæœ€å°åŒ–ã‚’ä¸¡ç«‹ã™ã‚‹å ±é…¬è¨­è¨ˆ
- å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¨å®šã—ãŸé·ç§»è¡Œåˆ—ã‚’ä½¿ç”¨
- base_markov-dqn-v09ã®é«˜å“è³ªå®Ÿè£…ã‚’å®Œå…¨çµ±åˆï¼ˆv2.0ï¼‰

## ã‚·ã‚¹ãƒ†ãƒ ãƒ•ãƒ­ãƒ¼å…¨ä½“å›³

```mermaid
flowchart TB
    subgraph Data["ğŸ“Š ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†"]
        A1["è¨­å‚™è«¸å…ƒCSV<br/>æ¸¬å®šå€¤CSV"] --> A2["data_preprocessor.py"]
        A2 --> A3["çµ±è¨ˆçš„é–¾å€¤è¨ˆç®—<br/>Î¼ Â± 2Ïƒ"]
        A3 --> A4["çŠ¶æ…‹åˆ†é¡<br/>Normal/Anomalous"]
        A4 --> A5["2x2é·ç§»è¡Œåˆ—æ¨å®š<br/>P = [[0.2948, 0.7052],<br/>     [0.0731, 0.9269]]"]
    end

    subgraph Env["ğŸ­ ç’°å¢ƒæ§‹ç¯‰"]
        B1["cbm_environment.py"]
        B2["Gymnasiumäº’æ›ç’°å¢ƒ"]
        B3["3ã¤ã®ä¿å…¨ã‚·ãƒŠãƒªã‚ª<br/>ãƒ»å®‰å…¨é‡è¦–<br/>ãƒ»ãƒãƒ©ãƒ³ã‚¹å‹<br/>ãƒ»ã‚³ã‚¹ãƒˆé‡è¦–"]
        B1 --> B2
        B2 --> B3
    end

    subgraph Train["ğŸ¤– QR-DQNå­¦ç¿’"]
        C1["train_cbm_dqn_v2.py"]
        C2["QR-DQN<br/>51 quantiles"]
        C3["æœ€é©åŒ–æ‰‹æ³•<br/>ãƒ»PER Î±=0.6<br/>ãƒ»N-step n=3<br/>ãƒ»AMP<br/>ãƒ»Parallel 16 envs<br/>ãƒ»Noisy Networks"]
        C4["å­¦ç¿’çµæœ<br/>policy_net.pth<br/>training_history.json"]
        C1 --> C2
        C2 --> C3
        C3 --> C4
    end

    subgraph Viz["ğŸ“ˆ å¯è¦–åŒ–"]
        D1["visualize_results.py"]
        D2["å­¦ç¿’æ›²ç·š<br/>åˆ†å¸ƒåˆ†æ<br/>VaR/CVaR"]
        D1 --> D2
    end

    subgraph Compare["ğŸ”¬ ã‚·ãƒŠãƒªã‚ªæ¯”è¼ƒ"]
        E1["compare_scenarios.py<br/>visualize_scenarios.py"]
        E2["3ã‚·ãƒŠãƒªã‚ªä¸¦åˆ—å®Ÿè¡Œ<br/>1000 episodes each"]
        E3["æ¯”è¼ƒçµæœ<br/>ãƒ»å®‰å…¨é‡è¦–: 8.45<br/>ãƒ»ãƒãƒ©ãƒ³ã‚¹å‹: 24.31 ğŸ†<br/>ãƒ»ã‚³ã‚¹ãƒˆé‡è¦–: -129.31"]
        E4["è©³ç´°å¯è¦–åŒ–<br/>ãƒ»å­¦ç¿’æ›²ç·šæ¯”è¼ƒ<br/>ãƒ»å„ã‚·ãƒŠãƒªã‚ªè©³ç´°<br/>  (2Ã—2ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ)"]
        E1 --> E2
        E2 --> E3
        E3 --> E4
    end

    subgraph Lessons["ğŸ“š æ•™è¨“"]
        F1["Scenario_Lessons.md"]
        F2["æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿<br/>risk_weight=1.0<br/>cost_lambda=0.15"]
        F3["å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ<br/>ãƒ»éå‰°ä¿å…¨<br/>ãƒ»ä¿å…¨ä¸è¶³"]
        F1 --> F2
        F1 --> F3
    end

    A5 --> B1
    B3 --> C1
    C4 --> D1
    C4 --> E1
    E4 --> F1

    style Data fill:#e3f2fd
    style Env fill:#f3e5f5
    style Train fill:#fff3e0
    style Viz fill:#e8f5e9
    style Compare fill:#fce4ec
    style Lessons fill:#fff9c4
```

**ãƒ•ãƒ­ãƒ¼ã®èª¬æ˜:**

1. **ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†**: CSVèª­ã¿è¾¼ã¿ â†’ çµ±è¨ˆçš„é–¾å€¤è¨ˆç®— â†’ çŠ¶æ…‹åˆ†é¡ â†’ é·ç§»è¡Œåˆ—æ¨å®š
2. **ç’°å¢ƒæ§‹ç¯‰**: Gymnasiumäº’æ›ç’°å¢ƒ + 3ã¤ã®ã‚·ãƒŠãƒªã‚ªè¨­å®š
3. **QR-DQNå­¦ç¿’**: åˆ†ä½ç‚¹å›å¸° + å„ç¨®æœ€é©åŒ–æ‰‹æ³•ã§å­¦ç¿’
4. **å¯è¦–åŒ–**: å­¦ç¿’æ›²ç·šã€åˆ†å¸ƒåˆ†æã€ãƒªã‚¹ã‚¯è©•ä¾¡
5. **ã‚·ãƒŠãƒªã‚ªæ¯”è¼ƒ**: 3ã¤ã®ä¿å…¨æˆ¦ç•¥ã‚’ä¸¦åˆ—å®Ÿè¡Œãƒ»æ¯”è¼ƒ
6. **æ•™è¨“**: æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ–‡æ›¸åŒ–

## ãƒ™ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰

- **å…ƒã‚³ãƒ¼ãƒ‰:** `base_markov-dqn-v09-quantile` ï¼ˆ3x3æ¨ç§»è¡Œåˆ—ã®æ©‹æ¢ä¿å…¨ï¼‰
- **é©å¿œ:** 2x2æ¨ç§»è¡Œåˆ—ï¼ˆè¨­å‚™CBMï¼‰ã«é©å¿œ

## ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ

```
equipment-cbm-mvp/
â”œâ”€â”€ data_preprocessor.py       # CSVãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ»å‰å‡¦ç†
â”œâ”€â”€ cbm_environment.py          # 2x2ãƒãƒ«ã‚³ãƒ•ç’°å¢ƒï¼ˆGymnasiumäº’æ›ï¼‰
â”œâ”€â”€ train_cbm_dqn.py           # QR-DQNå­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆæ—§ç‰ˆï¼‰
â”œâ”€â”€ train_cbm_dqn_v2.py        # QR-DQNå­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆv2.0ãƒ»æ¨å¥¨ï¼‰
â”œâ”€â”€ visualize_results.py       # çµæœå¯è¦–åŒ–
â”œâ”€â”€ requirements.txt           # ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
â””â”€â”€ README.md                  # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
```

## ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹

**å ´æ‰€:** `../data/private_benchmark/`

- `è¨­å‚™è«¸å…ƒ_å®Ÿæ¸¬å€¤100ä»¥ä¸Š.csv` - è¨­å‚™ã¨æ¸¬å®šé …ç›®ã®ãƒã‚¹ã‚¿
- `æ¸¬å®šå€¤examples_3è¨­å‚™_æ¸¬å®šé …ç›®_å®Ÿæ¸¬å€¤_20251217.csv` - æ™‚ç³»åˆ—æ¸¬å®šãƒ‡ãƒ¼ã‚¿

**MVPå¯¾è±¡:**
- è¨­å‚™: ãƒœã‚¤ãƒ©ãƒ¼(40t) (è¨­å‚™ID: 43175)
- æ¸¬å®šé …ç›®: æ¸©åº¦_å—æ±éƒ¨ä¸Šå´å£â‘¡ (æ¸¬å®šé …ç›®ID: 167473)

## çŠ¶æ…‹å®šç¾©

CSVã«å«ã¾ã‚Œã‚‹ä¸Šé™å€¤Smaxãƒ»ä¸‹é™å€¤Sminã‚’ä½¿ç”¨ï¼š

- **Normal (0):** `Smin â‰¤ å®Ÿæ¸¬å€¤ â‰¤ Smax`
- **Anomalous (1):** ãã‚Œä»¥å¤–

### çµ±è¨ˆçš„é–¾å€¤è¨ˆç®—ï¼ˆæ¬ æå€¤å¯¾å¿œï¼‰

ä¸‹é™å€¤Sminã¾ãŸã¯SmaxãŒæ¬ æã—ã¦ã„ã‚‹å ´åˆã€éå»ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆé‡ã‹ã‚‰è‡ªå‹•è¨ˆç®—ï¼š

```
Î¼ = å®Ÿæ¸¬å€¤ã®å¹³å‡
Ïƒ = å®Ÿæ¸¬å€¤ã®æ¨™æº–åå·®
k = 2.0ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰

Smin = Î¼ - kÃ—Ïƒ
Smax = Î¼ + kÃ—Ïƒ
```

**ãƒœã‚¤ãƒ©ãƒ¼æ¸©åº¦ãƒ‡ãƒ¼ã‚¿ã®å®Ÿä¾‹:**
- æ¸¬å®šé …ç›®: æ¸©åº¦_å—æ±éƒ¨ä¸Šå´å£â‘¡ (ID: 167473)
- ãƒ‡ãƒ¼ã‚¿æ•°: 1,843ãƒã‚¤ãƒ³ãƒˆ
- çµ±è¨ˆçš„ã«è¨ˆç®—ã•ã‚ŒãŸSmin: **13.02Â°C** (å…ƒãƒ‡ãƒ¼ã‚¿ã¯æ¬ æ)
- CSVã«å­˜åœ¨ã™ã‚‹Smax: **40.0Â°C**
- çµæœã®çŠ¶æ…‹åˆ†å¸ƒ:
  - Normal: 173ä»¶ (9.4%)
  - Anomalous: 1,670ä»¶ (90.6%)

## ãƒãƒ«ã‚³ãƒ•çŠ¶æ…‹é·ç§»

2x2é·ç§»è¡Œåˆ—:

```
P = [[p_nn, p_na],   # Normal â†’ [Normal, Anomalous]
     [p_an, p_aa]]   # Anomalous â†’ [Normal, Anomalous]
```

å®Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é·ç§»å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã—ã¦æ¨å®šã€‚

**ãƒœã‚¤ãƒ©ãƒ¼æ¸©åº¦ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¨å®šã•ã‚ŒãŸé·ç§»è¡Œåˆ—:**

```
P = [[0.2948, 0.7052],   # Normal â†’ [Normal, Anomalous]
     [0.0731, 0.9269]]   # Anomalous â†’ [Normal, Anomalous]
```

**ç‰¹å¾´:**
- NormalçŠ¶æ…‹ã¯ä¸å®‰å®šï¼ˆ70%ã®ç¢ºç‡ã§Anomalousã«é·ç§»ï¼‰
- AnomalousçŠ¶æ…‹ã¯æŒç¶šçš„ï¼ˆ93%ã®ç¢ºç‡ã§ç¶™ç¶šï¼‰
- Anomalousã‹ã‚‰ã®å›å¾©ã¯å›°é›£ï¼ˆ7%ã®ç¢ºç‡ã§Normalã«å¾©å¸°ï¼‰
- â†’ **ç©æ¥µçš„ãªä¿å…¨ä»‹å…¥ãŒå¿…è¦ãªè¨­å‚™ç‰¹æ€§**

## è¡Œå‹•ç©ºé–“

- **0: DoNothing** - ç¶™ç¶šé‹è»¢ï¼ˆã‚³ã‚¹ãƒˆ0ï¼‰
- **1: Repair** - ä¿®ç†ï¼ˆã‚³ã‚¹ãƒˆ3ã€normalå¾©å¸°ç¢ºç‡é«˜ï¼‰
- **2: Replace** - äº¤æ›ï¼ˆã‚³ã‚¹ãƒˆ8ã€normalå¾©å¸°ç¢ºç‡æœ€é«˜ï¼‰

## å ±é…¬é–¢æ•°

### ãƒªã‚¹ã‚¯æˆåˆ†

- NormalçŠ¶æ…‹: **+1**
- AnomalousçŠ¶æ…‹: **-10**

### ã‚³ã‚¹ãƒˆæˆåˆ†

- DoNothing: **0**
- Repair: **-3 Ã— Î»**
- Replace: **-8 Ã— Î»**

**åˆè¨ˆå ±é…¬:** `R = R_risk + R_cost`

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### 1. ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
pip install -r requirements.txt
```

### 2. ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ï¼ˆå‹•ä½œç¢ºèªï¼‰

```bash
python data_preprocessor.py
```

**å®Ÿéš›ã®å‡ºåŠ›:**
```
âœ… è¨­å‚™è«¸å…ƒèª­ã¿è¾¼ã¿: 580 è¡Œ
âœ… æ¸¬å®šå€¤èª­ã¿è¾¼ã¿: 247162 è¡Œ

ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªæ©Ÿæ¢°è¨­å‚™ä¸€è¦§
  è¨­å‚™id                   è¨­å‚™å  æ¸¬å®šé …ç›®æ•°  ç·æ¸¬å®šå›æ•°
 43175             ãƒœã‚¤ãƒ©ãƒ¼(40t)     17  17760
 43124                è’¸æ°—ã‚¿ãƒ¼ãƒ“ãƒ³     13  16445
 43114                  è„±ç¡«è£…ç½®      4   5060
...

ğŸ”¥ ãƒœã‚¤ãƒ©ãƒ¼(40t) [è¨­å‚™ID: 43175] ã®æ¸¬å®šé …ç›®
 æ¸¬å®šé …ç›®id         æ¸¬å®šæŒ‡æ¨™  æ¸¬å®šå›æ•°  æœ€æ–°ã®å®Ÿæ¸¬å€¤
 167472    æ¸©åº¦_å—æ±éƒ¨å¤©äº•â‘   1843    27.7
 167473   æ¸©åº¦_å—æ±éƒ¨ä¸Šå´å£â‘¡  1843    58.7
 167474   æ¸©åº¦_å—æ±éƒ¨ä¸‹å´å£â‘¢  1843    30.2
...

ğŸ¯ MVPå¯¾è±¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†

ğŸ“Š ãƒ‡ãƒ¼ã‚¿æŠ½å‡º: 1843 ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ
   â„¹ï¸ ä¸‹é™å€¤SminãŒæ¬ æã®ãŸã‚çµ±è¨ˆçš„ã«è¨ˆç®—: 13.02 (Î¼ - 2.0Ïƒ)

âœ… è¨­å‚™: ãƒœã‚¤ãƒ©ãƒ¼(40t)
âœ… æ¸¬å®šé …ç›®: æ¸©åº¦_å—æ±éƒ¨ä¸Šå´å£â‘¡
âœ… é–¾å€¤: Smin=13.02, Smax=40.0

ğŸ“ˆ çŠ¶æ…‹åˆ†å¸ƒ:
  - Normal: 173 (9.4%)
  - Anomalous: 1670 (90.6%)

ğŸ”„ çŠ¶æ…‹é·ç§»è¡Œåˆ— (2x2):
  [[0.2948, 0.7052],  # normal â†’ [normal, anomalous]
   [0.0731, 0.9269]]  # anomalous â†’ [normal, anomalous]
```

**é‡è¦ãªçŸ¥è¦‹:**
- ä¸‹é™å€¤SminãŒæ¬ æã—ã¦ã„ãŸãŸã‚ã€çµ±è¨ˆçš„æ‰‹æ³•ï¼ˆÎ¼ - 2Ïƒï¼‰ã§è‡ªå‹•è¨ˆç®—
- è¨­å‚™ã¯90.6%ã®æ™‚é–“ã‚’AnomalousçŠ¶æ…‹ã§éã”ã—ã¦ãŠã‚Šã€é«˜ãƒªã‚¹ã‚¯çŠ¶æ…‹
- NormalçŠ¶æ…‹ã§ã‚‚70%ã®ç¢ºç‡ã§Anomalousã«é·ç§»ã™ã‚‹ä¸å®‰å®šã•
- ã“ã®ç‰¹æ€§ã«ã‚ˆã‚Šã€å¼·åŒ–å­¦ç¿’ã§ã®æœ€é©ä¿å…¨æ–¹ç­–ã®å­¦ç¿’ãŒé‡è¦

### 3. CBMç’°å¢ƒã®ãƒ†ã‚¹ãƒˆ

#### åŸºæœ¬ãƒ†ã‚¹ãƒˆï¼ˆã‚µãƒ³ãƒ—ãƒ«é·ç§»è¡Œåˆ—ï¼‰

```bash
python cbm_environment.py
```

**å‡ºåŠ›:**
```
âœ… Environment created
  - Action space: Discrete(3)
  - Observation space: Box(0.0, 1.0, (2,), float32)
  - Transition matrix:
[[0.96 0.04]
 [0.15 0.85]]

ğŸ¬ Initial: condition=Normal, temp=50.0Â°C
  Action: DoNothing  | Normal â†’ Normal     | Reward:   1.00 | Temp:  78.6Â°C
  ...
ğŸ“Š Episode Summary:
  - Total steps: 20
  - Total reward: -3.60
  - Actions: {'Replace': 2, 'DoNothing': 18}
```

#### å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆï¼ˆãƒœã‚¤ãƒ©ãƒ¼æ¨å®šé·ç§»è¡Œåˆ—ï¼‰

```bash
python quick_test.py
```

**å®Ÿéš›ã®å‡ºåŠ›:**
```
ğŸ­ Real Data Environment Test

âœ… Environment created with real data
   Transition probabilities:
     Normal â†’ Anomalous: 70.5%
     Anomalous â†’ Anomalous: 92.7%
   Temperature range: [11.5, 138.4]Â°C
   Normal range: [13.02, 40.0]Â°C

ğŸ¬ Test Episode (30 steps)
   Policy: Repair if Anomalous, DoNothing if Normal

Initial: Normal, Temp=23.1Â°C

 1. DoNothing  | Normal     â†’ Anomalous  | R:  1.00 | T: 98.9Â°C
 2. Repair     | Anomalous  â†’ Normal     | R:-10.30 | T: 17.2Â°C
 3. DoNothing  | Normal     â†’ Normal     | R:  1.00 | T: 36.4Â°C
 4. DoNothing  | Normal     â†’ Anomalous  | R:  1.00 | T: 42.0Â°C
 ...
30. Repair     | Anomalous  â†’ Anomalous  | R:-10.30 | T:111.7Â°C

ğŸ“Š Summary
Total reward: -128.20
Avg reward/step: -4.27
Actions: {'DoNothing': 16, 'Repair': 14, 'Replace': 0}
States: {'Normal': 16, 'Anomalous': 14}
State ratio: Normal 16/30 (53.3%)
```

**ãƒ†ã‚¹ãƒˆçµæœã®é‡è¦ãªçŸ¥è¦‹:**

âœ… **ç’°å¢ƒã®æ­£å¸¸å‹•ä½œç¢ºèª:**
- å®Ÿãƒ‡ãƒ¼ã‚¿é·ç§»è¡Œåˆ—ãŒæ­£ã—ãæ©Ÿèƒ½ï¼ˆNormalâ†’Anomalous 70.5%ï¼‰
- æ¸©åº¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¨CBMé–¾å€¤åˆ¤å®šãŒé©åˆ‡
- è¡Œå‹•ã«ã‚ˆã‚‹çŠ¶æ…‹é·ç§»ãŒæœŸå¾…é€šã‚Š

âš ï¸ **ç°¡æ˜“æ–¹ç­–ï¼ˆ"Anomalousãªã‚‰ä¿®ç†"ï¼‰ã®å•é¡Œç‚¹:**
- **ç·å ±é…¬: -128.20** ï¼ˆ30ã‚¹ãƒ†ãƒƒãƒ—ã§å¹³å‡-4.27/stepï¼‰
- 14å›ã®ä¿®ç†ã§éå‰°ãªã‚³ã‚¹ãƒˆç™ºç”Ÿ
- NormalçŠ¶æ…‹ã§ã‚‚70%ã§Anomalousã«é·ç§»ã™ã‚‹ãŸã‚ä¿®ç†ãŒè¿½ã„ã¤ã‹ãªã„
- ä¿®ç†ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã¨ä¿®ç†/äº¤æ›ã®é¸æŠãŒæœ€é©åŒ–ã•ã‚Œã¦ã„ãªã„

ğŸ’¡ **DQNå­¦ç¿’ã®å¿…è¦æ€§:**
å˜ç´”ãªãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹æ–¹ç­–ã§ã¯ã€ä»¥ä¸‹ãŒæœ€é©åŒ–ã§ããªã„:
- **ã„ã¤ä¿®ç†ã™ã¹ãã‹** - æ—©ã™ãã‚‹ä»‹å…¥ã¯ç„¡é§„ã€é…ã™ãã‚‹ã¨ãƒªã‚¹ã‚¯å¢—å¤§
- **ä¿®ç† vs äº¤æ›** - ã‚³ã‚¹ãƒˆå·®ã‚’è€ƒæ…®ã—ãŸé¸æŠ
- **é€£ç¶šçš„ãªç•°å¸¸ã®æ‰±ã„** - AnomalousæŒç¶šæ™‚ã®æœ€é©æˆ¦ç•¥
- **ãƒªã‚¹ã‚¯ã¨ã‚³ã‚¹ãƒˆã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•** - é•·æœŸçš„ãªæœŸå¾…å ±é…¬ã®æœ€å¤§åŒ–

â†’ QR-DQNã§åˆ†å¸ƒçš„ãªä¾¡å€¤ã‚’å­¦ç¿’ã—ã€æœ€é©ä¿å…¨æ–¹ç­–ã‚’ç™ºè¦‹ã™ã‚‹

## å­¦ç¿’å®Ÿè¡Œ

### å­¦ç¿’ãƒ•ãƒ­ãƒ¼è©³ç´°

```mermaid
flowchart LR
    subgraph Init["åˆæœŸåŒ–"]
        A1["ç’°å¢ƒä½œæˆ<br/>AsyncVectorEnv<br/>16 parallel"]
        A2["QR-DQN<br/>Dueling+Noisy"]
        A3["PER Buffer<br/>size=10000"]
    end

    subgraph Episode["ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ«ãƒ¼ãƒ—"]
        B1["çŠ¶æ…‹è¦³æ¸¬<br/>[condition, temp]"]
        B2["è¡Œå‹•é¸æŠ<br/>Noisy Networks<br/>æ¢ç´¢"]
        B3["ç’°å¢ƒå®Ÿè¡Œ<br/>16ä¸¦åˆ—"]
        B4["å ±é…¬è¨ˆç®—<br/>risk + cost"]
        B5["çµŒé¨“ä¿å­˜<br/>to PER"]
        B1 --> B2
        B2 --> B3
        B3 --> B4
        B4 --> B5
        B5 --> B1
    end

    subgraph Update["ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ›´æ–°"]
        C1["PER<br/>ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°<br/>å„ªå…ˆåº¦Î±=0.6"]
        C2["N-step TD<br/>n=3"]
        C3["Quantile<br/>Huber Loss"]
        C4["AMP<br/>FP16å­¦ç¿’"]
        C5["TargetåŒæœŸ<br/>500 steps"]
        C1 --> C2
        C2 --> C3
        C3 --> C4
        C4 --> C5
    end

    subgraph Output["å‡ºåŠ›"]
        D1["policy_net.pth"]
        D2["training_history<br/>.json"]
        D3["å­¦ç¿’æ›²ç·š<br/>å¯è¦–åŒ–"]
    end

    A1 --> B1
    A2 --> B2
    A3 --> C1
    B5 --> C1
    C5 --> D1
    B4 --> D2
    D1 --> D3
    D2 --> D3

    style Init fill:#e3f2fd
    style Episode fill:#fff3e0
    style Update fill:#f3e5f5
    style Output fill:#e8f5e9
```

**æœ€é©åŒ–æŠ€è¡“:**
- **PER**: é‡è¦ãªçµŒé¨“ã‚’å„ªå…ˆçš„ã«å­¦ç¿’ï¼ˆÎ±=0.6, Î²: 0.4â†’1.0ï¼‰
- **N-step**: 3ã‚¹ãƒ†ãƒƒãƒ—å…ˆã‚’è¦‹æ®ãˆãŸä¾¡å€¤æ¨å®š
- **AMP**: æ··åˆç²¾åº¦ã§GPUé«˜é€ŸåŒ–
- **Noisy Networks**: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã§ã®æ¢ç´¢ã€Îµ-greedyä¸è¦
- **AsyncVectorEnv**: 16ç’°å¢ƒä¸¦åˆ—ã§45å€é«˜é€ŸåŒ–

### v2.0ï¼ˆæ¨å¥¨ï¼‰- å®Œå…¨æœ€é©åŒ–ç‰ˆ

**ç‰¹å¾´:**
- âœ… Prioritized Experience Replay (PER)
- âœ… N-step Learning (n=3)
- âœ… Mixed Precision Training (AMP)
- âœ… AsyncVectorEnv ä¸¦åˆ—å‡¦ç†ï¼ˆ16ç’°å¢ƒï¼‰
- âœ… Noisy Networksï¼ˆÎµ-greedyãªã—ï¼‰
- âœ… **45å€é«˜é€ŸåŒ–** (0.142ç§’/episode vs æ—§ç‰ˆ1.08ç§’/episode)

```bash
python train_cbm_dqn_v2.py --episodes 1000 --n_envs 16
```

**å®Ÿè¡Œçµæœï¼ˆ200ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ï¼‰:**
```
================================================================================
EQUIPMENT CBM QR-DQN TRAINING (v2.0)
================================================================================
Configuration:
  Episodes: 200, Parallel Envs: 16
  Device: cuda, Gamma: 0.95, LR: 0.0015
  Buffer: 10000, Batch: 64
  Target Sync: 500 steps

Optimizations:
  âœ“ QR-DQN (Quantiles=51)
  âœ“ Prioritized Experience Replay (Î±=0.6, Î²=0.4)
  âœ“ N-step Learning (n=3)
  âœ“ Mixed Precision Training (AMP)
  âœ“ AsyncVectorEnv (16 parallel)
  âœ“ Noisy Networks (no Îµ-greedy)
================================================================================

ğŸ“Š Episode 100/200
   Avg Reward (last 100): 5.50
   Avg Loss (last 1000): 5.7449
   Time: 15.7s (0.157s/ep)

ğŸ“Š Episode 200/200
   Avg Reward (last 100): -14.82
   Avg Loss (last 1000): 1.8879
   Time: 27.3s (0.136s/ep)

================================================================================
TRAINING COMPLETE
================================================================================
Total Episodes: 200
Total Time: 28.37 sec (0.47 min)
Time per Episode: 0.142 sec
Final Reward (last 100): -14.82
================================================================================
```

**ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ:**
- **v2.0:** 0.142ç§’/episodeï¼ˆ200 episodes / 28.37ç§’ï¼‰
- **æ—§ç‰ˆ:** 1.08ç§’/episodeï¼ˆæ¨å®šï¼‰
- **é«˜é€ŸåŒ–:** ç´„45å€

**å­¦ç¿’åŠ¹æœ:**
- **ç°¡æ˜“æ–¹ç­–ï¼ˆãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰:** -128.20å ±é…¬ï¼ˆ30ã‚¹ãƒ†ãƒƒãƒ—ï¼‰
- **v2.0å­¦ç¿’æ¸ˆã¿æ–¹ç­–:** -14.82å ±é…¬ï¼ˆæœ€çµ‚100ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å¹³å‡ï¼‰
- **æ”¹å–„:** ç´„88%ã®å ±é…¬å‘ä¸Šï¼ˆãƒªã‚¹ã‚¯å‰Šæ¸›ã¨ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã‚’é”æˆï¼‰

### ã‚ªãƒ—ã‚·ãƒ§ãƒ³

```bash
python train_cbm_dqn_v2.py \
  --equipment_id 43175 \
  --measurement_id 167473 \
  --episodes 1000 \
  --n_envs 16 \
  --horizon 100 \
  --lr 1.5e-3 \
  --gamma 0.95 \
  --batch_size 64 \
  --buffer_size 10000 \
  --n_quantiles 51 \
  --seed 42 \
  --output_dir outputs_cbm_v2
```

**ä¸»è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `--episodes`: å­¦ç¿’ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1000ï¼‰
- `--n_envs`: ä¸¦åˆ—ç’°å¢ƒæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 16ï¼‰
- `--horizon`: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰é•·ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 100ã‚¹ãƒ†ãƒƒãƒ—ï¼‰
- `--lr`: å­¦ç¿’ç‡ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1.5e-3ï¼‰
- `--gamma`: å‰²å¼•ç‡ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.95ï¼‰
- `--batch_size`: ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 64ï¼‰
- `--buffer_size`: ãƒªãƒ—ãƒ¬ã‚¤ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10000ï¼‰
- `--n_quantiles`: åˆ†ä½ç‚¹æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 51ï¼‰

### å­¦ç¿’å‡ºåŠ›

`outputs_cbm_v2/` ã«ä»¥ä¸‹ãŒä¿å­˜ã•ã‚Œã¾ã™ï¼š

- `policy_net.pth` - å­¦ç¿’æ¸ˆã¿DQNãƒ¢ãƒ‡ãƒ«
- `training_history.json` - å­¦ç¿’å±¥æ­´ï¼ˆå ±é…¬ã€æå¤±ã€ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰é•·ï¼‰

### æ—§ç‰ˆï¼ˆv1.0ï¼‰

åŸºæœ¬çš„ãªå®Ÿè£…ï¼ˆä¸¦åˆ—å‡¦ç†ãªã—ï¼‰:

```bash
python train_cbm_dqn.py --episodes 2000 --output_dir outputs_cbm
```

âš ï¸ **æ³¨æ„:** v2.0ã®ä½¿ç”¨ã‚’æ¨å¥¨ã—ã¾ã™ï¼ˆ45å€é«˜é€Ÿ + PER/N-step/AMPæœ€é©åŒ–ï¼‰

## ã‚·ãƒŠãƒªã‚ªæ¯”è¼ƒ

### 3ã¤ã®ä¿å…¨ã‚·ãƒŠãƒªã‚ª

```mermaid
flowchart TB
    subgraph Scenarios["ä¿å…¨ã‚·ãƒŠãƒªã‚ª"]
        S1["å®‰å…¨é‡è¦–<br/>risk_weight=1.0<br/>cost_lambda=0.05<br/>ç©æ¥µçš„ä¿å…¨"]
        S2["ãƒãƒ©ãƒ³ã‚¹å‹<br/>risk_weight=1.0<br/>cost_lambda=0.15<br/>æœ€é©ãƒãƒ©ãƒ³ã‚¹"]
        S3["ã‚³ã‚¹ãƒˆé‡è¦–<br/>risk_weight=0.3<br/>cost_lambda=0.5<br/>æœ€å°é™ä¿å…¨"]
    end

    subgraph Train["ä¸¦åˆ—è¨“ç·´"]
        T1["1000 episodes<br/>16 parallel envs<br/>~2 min/scenario"]
    end

    subgraph Results["è¨“ç·´çµæœ"]
        R1["å®‰å…¨é‡è¦–<br/>æœ€çµ‚å ±é…¬: 8.45<br/>Std: 37.38<br/>âš ï¸ ä¸å®‰å®š"]
        R2["ãƒãƒ©ãƒ³ã‚¹å‹<br/>æœ€çµ‚å ±é…¬: 24.31<br/>Std: 26.71<br/>ğŸ† æœ€å„ªç§€"]
        R3["ã‚³ã‚¹ãƒˆé‡è¦–<br/>æœ€çµ‚å ±é…¬: -129.31<br/>Std: 17.60<br/>âŒ å®Œå…¨å¤±æ•—"]
    end

    subgraph Analysis["æ¯”è¼ƒåˆ†æ"]
        A1["å­¦ç¿’æ›²ç·šæ¯”è¼ƒ"]
        A2["å„ã‚·ãƒŠãƒªã‚ªè©³ç´°<br/>ãƒ»ç”Ÿå ±é…¬<br/>ãƒ»ç§»å‹•å¹³å‡<br/>ãƒ»åˆ†å¸ƒ<br/>ãƒ»ç´¯ç©å¹³å‡"]
        A3["æœ€çµ‚æ€§èƒ½<br/>æ£’ã‚°ãƒ©ãƒ•"]
    end

    subgraph Insights["æ•™è¨“"]
        I1["âœ… Lambda=0.15ãŒæœ€é©"]
        I2["âš ï¸ Lambda<0.1: éå‰°ä¿å…¨"]
        I3["âŒ Lambda>0.3: ä¿å…¨ä¸è¶³"]
        I4["âŒ Risk Weight<0.5: å­¦ç¿’å¤±æ•—"]
    end

    S1 --> T1
    S2 --> T1
    S3 --> T1
    T1 --> R1
    T1 --> R2
    T1 --> R3
    R1 --> A1
    R2 --> A1
    R3 --> A1
    A1 --> A2
    A2 --> A3
    A3 --> I1
    A3 --> I2
    A3 --> I3
    A3 --> I4

    style S2 fill:#c8e6c9
    style R2 fill:#c8e6c9
    style I1 fill:#c8e6c9
    style R1 fill:#fff9c4
    style I2 fill:#fff9c4
    style R3 fill:#ffcdd2
    style I3 fill:#ffcdd2
    style I4 fill:#ffcdd2
```

### å®Ÿè¡Œæ–¹æ³•

**å€‹åˆ¥ã‚·ãƒŠãƒªã‚ªå®Ÿè¡Œ:**
```bash
# å®‰å…¨é‡è¦–
python train_cbm_dqn_v2.py --scenario safety_first --episodes 1000

# ãƒãƒ©ãƒ³ã‚¹å‹ï¼ˆæ¨å¥¨ï¼‰
python train_cbm_dqn_v2.py --scenario balanced --episodes 1000

# ã‚³ã‚¹ãƒˆé‡è¦–
python train_cbm_dqn_v2.py --scenario cost_efficient --episodes 1000
```

**ä¸€æ‹¬æ¯”è¼ƒå®Ÿè¡Œ:**
```bash
# 3ã‚·ãƒŠãƒªã‚ªã‚’é †æ¬¡å®Ÿè¡Œã—ã¦æ¯”è¼ƒï¼ˆç´„6åˆ†ï¼‰
python compare_scenarios.py
```

**æ—¢å­˜çµæœã®å¯è¦–åŒ–ã®ã¿:**
```bash
# å†è¨“ç·´ã›ãšã«å¯è¦–åŒ–ã ã‘å®Ÿè¡Œ
python visualize_scenarios.py
```

### æ¯”è¼ƒçµæœã‚µãƒãƒªãƒ¼

| ã‚·ãƒŠãƒªã‚ª | å¹³å‡å ±é…¬ | æœ€çµ‚100å¹³å‡ | æœ€å¤§å ±é…¬ | æ¨™æº–åå·® | è©•ä¾¡ |
|---------|---------|------------|---------|---------|------|
| **ğŸ† ãƒãƒ©ãƒ³ã‚¹å‹** | **26.36** | **24.31** | **55.00** | 26.71 | æœ€å„ªç§€ |
| å®‰å…¨é‡è¦– | 5.35 | 8.45 | 25.00 | 37.38 | ä¸å®‰å®š |
| ã‚³ã‚¹ãƒˆé‡è¦– | -134.25 | -129.31 | -117.30 | 17.60 | å¤±æ•— |

**ç”Ÿæˆã•ã‚Œã‚‹å¯è¦–åŒ–:**
- `outputs_comparison/scenario_comparison.png` - 3ã‚·ãƒŠãƒªã‚ªæ¯”è¼ƒï¼ˆå­¦ç¿’æ›²ç·š + æœ€çµ‚æ€§èƒ½ï¼‰
- `outputs_comparison/balanced_detailed.png` - ãƒãƒ©ãƒ³ã‚¹å‹è©³ç´°ï¼ˆ2Ã—2ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆï¼‰
- `outputs_comparison/safety_first_detailed.png` - å®‰å…¨é‡è¦–è©³ç´°
- `outputs_comparison/cost_efficient_detailed.png` - ã‚³ã‚¹ãƒˆé‡è¦–è©³ç´°

**è©³ç´°åˆ†æ:** [Scenario_Lessons.md](Scenario_Lessons.md) ã‚’å‚ç…§

## çµæœå¯è¦–åŒ–

```bash
python visualize_results.py --output_dir outputs_cbm
```

**ç”Ÿæˆã•ã‚Œã‚‹ã‚°ãƒ©ãƒ•:**

1. **training_history.png** - å­¦ç¿’é€²æ—
   - ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å ±é…¬ã®æ¨ç§»
   - ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰é•·ã®æ¨ç§»
   - æå¤±ã®æ¨ç§»
   - å ±é…¬åˆ†å¸ƒ

2. **transition_matrix.png** - çŠ¶æ…‹é·ç§»è¡Œåˆ—ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—

3. **policy_evaluation.png** - å­¦ç¿’æ¸ˆã¿æ–¹ç­–ã®è©•ä¾¡
   - è¡Œå‹•åˆ†å¸ƒ
   - çŠ¶æ…‹åˆ†å¸ƒ
   - ã‚µãƒ³ãƒ—ãƒ«ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®è»Œè·¡
   - ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰åˆ¥å ±é…¬

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ 

**QR-DQN (Quantile Regression DQN) with Dueling Architecture:**

```
Input: [condition, normalized_temp] (2-dim)
  â†“
Shared Layers: [128, 64]
  â†“
  â”œâ”€ Value Stream (NoisyLinear):  [64] â†’ [64] â†’ [n_quantiles]
  â””â”€ Advantage Stream (NoisyLinear): [64] â†’ [64] â†’ [3 Ã— n_quantiles]
  â†“
Dueling Combination: Q = V + (A - mean(A))
  â†“
Output: Q-values for [DoNothing, Repair, Replace]
```

### ä¸»è¦æŠ€è¡“

1. **Quantile Regression DQN** (Dabney et al., AAAI 2018)
   - åˆ†å¸ƒå‹å¼·åŒ–å­¦ç¿’
   - å›ºå®šåˆ†ä½ç‚¹ã§Qå€¤ã®åˆ†å¸ƒã‚’å­¦ç¿’
   - Quantile Huber Lossã§é ‘å¥ãªå­¦ç¿’

2. **Noisy Networks** (Fortunato et al., ICLR 2018)
   - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã§ã®æ¢ç´¢
   - Îµ-greedyã‚’ä½¿ã‚ãªã„è‡ªå‹•æ¢ç´¢

3. **Dueling Architecture** (Wang et al., ICML 2016)
   - çŠ¶æ…‹ä¾¡å€¤ã¨è¡Œå‹•ä¾¡å€¤ã‚’åˆ†é›¢
   - å­¦ç¿’ã®å®‰å®šåŒ–

4. **Double DQN** (van Hasselt et al., AAAI 2016)
   - Qå€¤ã®éå¤§è©•ä¾¡ã‚’æŠ‘åˆ¶

### v2.0ã®è¿½åŠ æœ€é©åŒ–

5. **Prioritized Experience Replay** (Schaul et al., ICLR 2016)
   - TDèª¤å·®ã«åŸºã¥ãå„ªå…ˆåº¦ä»˜ãã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
   - é‡è¦ãªçµŒé¨“ã‹ã‚‰åŠ¹ç‡çš„ã«å­¦ç¿’
   - Importance Samplingè£œæ­£ã§ãƒã‚¤ã‚¢ã‚¹é™¤å»
   - Parameters: Î±=0.6, Î²=0.4â†’1.0 (annealing)

6. **N-step Learning**
   - ãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ—ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ï¼ˆn=3ï¼‰
   - æ™‚é–“çš„ä¿¡ç”¨å‰²å½“ã®åŠ é€Ÿ
   - Gammaèª¿æ•´: Î³^n for n-step returns

7. **Mixed Precision Training (AMP)**
   - FP16/FP32æ··åˆç²¾åº¦æ¼”ç®—
   - GPUãƒ¡ãƒ¢ãƒªåŠ¹ç‡å‘ä¸Š
   - å­¦ç¿’é€Ÿåº¦ã®é«˜é€ŸåŒ–
   - GradScalerã«ã‚ˆã‚‹å‹¾é…ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

8. **AsyncVectorEnv ä¸¦åˆ—åŒ–**
   - 16ç’°å¢ƒã®ä¸¦åˆ—å®Ÿè¡Œ
   - ãƒ‡ãƒ¼ã‚¿åé›†ã®é«˜é€ŸåŒ–ï¼ˆ16å€ï¼‰
   - å¤šæ§˜ãªçµŒé¨“ã®åŒæ™‚åé›†

## å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ

### çŠ¶æ…‹è¦³æ¸¬

```python
observation = [
    condition,              # 0=Normal, 1=Anomalous
    normalized_temperature  # 0~1ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
]
```

### é·ç§»ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹

- **DoNothingæ™‚:** ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¨å®šã—ãŸé·ç§»è¡Œåˆ—ã‚’ä½¿ç”¨
- **Repairæ™‚:** Normalå¾©å¸°ç¢ºç‡ã‚’é«˜ã‚ãŸé·ç§»è¡Œåˆ—
- **Replaceæ™‚:** Normalå¾©å¸°ç¢ºç‡ã‚’æœ€å¤§åŒ–ã—ãŸé·ç§»è¡Œåˆ—

### æ¸©åº¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°

- **NormalçŠ¶æ…‹:** `[Smin, Smax]` ã®ç¯„å›²å†…ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
- **AnomalousçŠ¶æ…‹:** ç¯„å›²å¤–ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆä¸Šé™è¶…é or ä¸‹é™æœªæº€ï¼‰

### v2.0ã®å®Ÿè£…è©³ç´°

#### Prioritized N-step Buffer

```python
class PrioritizedNStepBuffer:
    def __init__(self, capacity, n_steps=3, gamma=0.95, 
                 alpha=0.6, beta=0.4, beta_increment=0.001):
        # N-stepãƒãƒƒãƒ•ã‚¡ã§ãƒªã‚¿ãƒ¼ãƒ³ã‚’ç´¯ç©
        # TDèª¤å·®ã«åŸºã¥ãå„ªå…ˆåº¦ç®¡ç†
        # Importance Sampling weightsè¨ˆç®—
```

**N-stepãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—:**
```python
n_step_reward = Î£(Î³^i Ã— r_i) for i in [0, n)
target = n_step_reward + Î³^n Ã— Q_target(s', a')
```

#### Quantile Huber Loss with PER

```python
def quantile_huber_loss_per(
    policy_net, target_net, states, actions, rewards, 
    next_states, dones, weights, gamma, kappa=1.0, n_steps=3
):
    # Quantile regression loss
    # Importance sampling weightsé©ç”¨
    # TDèª¤å·®ã‚’è¿”ã™ï¼ˆå„ªå…ˆåº¦æ›´æ–°ç”¨ï¼‰
```

#### Mixed Precision Training

```python
scaler = GradScaler('cuda')

with autocast('cuda'):
    loss, td_errors = quantile_huber_loss_per(...)

scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

#### ä¸¦åˆ—ç’°å¢ƒã‚¹ãƒ†ãƒƒãƒ—

```python
# 16ç’°å¢ƒåŒæ™‚ã«è¡Œå‹•é¸æŠ
actions = agent_net(states).argmax(dim=1)

# 16ç’°å¢ƒåŒæ™‚ã«ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ
next_states, rewards, dones, _, _ = envs.step(actions)

# å„ç’°å¢ƒã®é·ç§»ã‚’ãƒãƒƒãƒ•ã‚¡ã«æ ¼ç´
for i in range(n_envs):
    buffer.push(states[i], actions[i], rewards[i], ...)
```

## æ‹¡å¼µã®æ–¹å‘æ€§

### çŸ­æœŸçš„æ”¹å–„

1. **å¤–çš„è¦å› ã®è¿½åŠ **
   -å…¨ãƒ‡ãƒ¼ã‚¿ãŒAnomalousã«ãªã‚‹

```
ğŸ“ˆ çŠ¶æ…‹åˆ†å¸ƒ:
  - Normal: 0 (0.0%)
  - Anomalous: 1843 (100.0%)
```

**åŸå› :** ä¸‹é™å€¤Sminã¾ãŸã¯SmaxãŒNaNï¼ˆæ¬ æå€¤ï¼‰ã§ã€çµ±è¨ˆçš„è¨ˆç®—ãŒè¡Œã‚ã‚Œã¦ã„ãªã„

**è§£æ±ºç­–:** æœ€æ–°ç‰ˆã®data_preprocessor.pyã¯è‡ªå‹•ã§çµ±è¨ˆçš„é–¾å€¤ã‚’è¨ˆç®—ã—ã¾ã™
- ä¸‹é™å€¤Smin = Î¼ - 2Ïƒ
- ä¸Šé™å€¤Smax = Î¼ + 2Ïƒ

çµ±è¨ˆçš„è¨ˆç®—ã®kÏƒå€¤ã‚’å¤‰æ›´ã—ãŸã„å ´åˆ:
```python
df = preprocessor.label_states(df, k_sigma=3.0)  # ã‚ˆã‚Šåºƒã„ç¯„å›²
```

###  ç¨¼åƒæ™‚é–“ï¼ˆutilizationï¼‰
   - çµŒå¹´åŠ£åŒ–ï¼ˆage/lifetimeï¼‰

2. **å ±é…¬é–¢æ•°ã®èª¿æ•´**
   - ãƒªã‚¹ã‚¯ãƒ»ã‚³ã‚¹ãƒˆãƒãƒ©ãƒ³ã‚¹ã®æœ€é©åŒ–
   - å¤–çš„è¦å› ã«ä¾å­˜ã—ãŸå‹•çš„å ±é…¬

3. **è¤‡æ•°æ¸¬å®šé …ç›®ã®çµ±åˆ**
   - æ¸©åº¦ã ã‘ã§ãªãåœ§åŠ›ãƒ»æµé‡ãªã©ã‚‚å«ã‚ã‚‹

### é•·æœŸçš„ç™ºå±•

1. **ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŒ–**
   - è¤‡æ•°è¨­å‚™ã®åŒæ™‚æœ€é©åŒ–
   - äºˆç®—åˆ¶ç´„ä¸‹ã§ã®å„ªå…ˆé †ä½ä»˜ã‘

2. **å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã®æ¤œè¨¼**
   - ã‚ˆã‚Šé•·æœŸé–“ã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿
   - å®Ÿéš›ã®ä¿å…¨è¨˜éŒ²ã¨ã®ç…§åˆ

3. **éšå±¤çš„æ„æ€æ±ºå®š**
   - è¨­å‚™ãƒ¬ãƒ™ãƒ«ãƒ»å·¥å ´ãƒ¬ãƒ™ãƒ«ã®éšå±¤åŒ–
   - ç‚¹æ¤œã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æœ€é©åŒ–

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„

```
ValueError: ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: è¨­å‚™ID=..., æ¸¬å®šé …ç›®ID=...
```

â†’ `data_preprocessor.py` ã§åˆ©ç”¨å¯èƒ½ãªè¨­å‚™ãƒ»æ¸¬å®šé …ç›®ã‚’ç¢ºèª

### GPUä½¿ç”¨æ™‚ã®ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼

```
RuntimeError: CUDA out of memory
```

â†’ `--batch_size` ã‚’å°ã•ãã™ã‚‹ï¼ˆä¾‹: 32ï¼‰

### å­¦ç¿’ãŒä¸å®‰å®š

- å­¦ç¿’ç‡ã‚’ä¸‹ã’ã‚‹: `--lr 5e-5`
- å‰²å¼•ç‡ã‚’èª¿æ•´: `--gamma 0.9`
- ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰é•·ã‚’çŸ­ãã™ã‚‹: `--horizon 50`

## å‚è€ƒæ–‡çŒ®

1. **QR-DQN:** Dabney et al. "Distributional Reinforcement Learning with Quantile Regression" (AAAI 2018)
2. **Noisy Networks:** Fortunato et al. "Noisy Networks for Exploration" (ICLR 2018)
3. **Dueling DQN:** Wang et al. "Dueling Network Architectures for Deep Reinforcement Learning" (ICML 2016)
4. **Double DQN:** van Hasselt et al. "Deep Reinforcement Learning with Double Q-learning" (AAAI 2016)
5. **Prioritized Experience Replay:** Schaul et al. "Prioritized Experience Replay" (ICLR 2016)
6. **Multi-step Learning:** Sutton & Barto "Reinforcement Learning: An Introduction" (2nd ed., 2018)

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT License

## ä½œæˆæ—¥

2025å¹´12æœˆ21æ—¥
