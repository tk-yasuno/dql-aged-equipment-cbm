"""
2x2 Markov CBM Environment for Equipment Maintenance

Features:
- 2x2 state transition: Normal / Anomalous
- Actions: DoNothing, Repair, Replace
- Reward: Risk suppression + Cost minimization
- Based on: base_markov-dqn-v09-quantile/src/markov_fleet_environment.py

State Definition:
- condition: 0=normal, 1=anomalous (based on CBM thresholds)
- temperature: normalized temperature value

Action Space:
- 0: Do Nothing (continue operation)
- 1: Repair (reset to normal, medium cost)
- 2: Replace (reset to normal, high cost)

Reward Function:
- Risk component: +1 for normal, -10 for anomalous
- Cost component: 0 for do nothing, -3 for repair, -8 for replace
"""

from typing import Optional, Tuple, Dict
import numpy as np
import gymnasium as gym
from gymnasium import spaces


# ----- Constants -----

STATE_NAMES = ["Normal", "Anomalous"]  # 0, 1
ACTION_NAMES = ["DoNothing", "Repair", "Replace"]  # 0, 1, 2

# Default 2x2 transition matrix (will be updated from real data)
DEFAULT_TRANSITIONS = {
    0: np.array([  # DoNothing
        [0.95, 0.05],  # from Normal â†’ [Normal, Anomalous]
        [0.10, 0.90],  # from Anomalous â†’ [Normal, Anomalous]
    ], dtype=np.float32),
    1: np.array([  # Repair
        [0.98, 0.02],  # from Normal â†’ [Normal, Anomalous] (slightly improved)
        [0.80, 0.20],  # from Anomalous â†’ [Normal, Anomalous] (high recovery)
    ], dtype=np.float32),
    2: np.array([  # Replace
        [0.99, 0.01],  # from Normal â†’ [Normal, Anomalous] (best state)
        [0.95, 0.05],  # from Anomalous â†’ [Normal, Anomalous] (almost full recovery)
    ], dtype=np.float32),
}

# Action costs (relative units)
ACTION_COSTS = np.array([
    0.0,   # DoNothing
    3.0,   # Repair
    15.0,  # Replace (increased for realism)
], dtype=np.float32)

# Maintenance Scenario Presets
MAINTENANCE_SCENARIOS = {
    'safety_first': {
        'risk_weight': 1.0,
        'cost_lambda': 0.05,  # Low cost penalty
        'description': 'å®‰å…¨é‡è¦–ï¼šè¨­å‚™åœæ­¢ã‚’å›é¿ã—ã€ç©æ¥µçš„ã«ä¿å…¨'
    },
    'cost_efficient': {
        'risk_weight': 0.3,
        'cost_lambda': 0.5,   # High cost penalty
        'description': 'ã‚³ã‚¹ãƒˆé‡è¦–ï¼šè¨­å‚™ä¸­æ–­ã‚’è¨±å®¹ã—ã€å¿…è¦æœ€å°é™ã®ä¿å…¨'
    },
    'balanced': {
        'risk_weight': 1.0,
        'cost_lambda': 0.15,  # Medium cost penalty
        'description': 'ãƒãƒ©ãƒ³ã‚¹å‹ï¼šå®‰å…¨ã¨ã‚³ã‚¹ãƒˆã‚’ä¸¡ç«‹ã—ãŸä¿å…¨æˆ¦ç•¥'
    }
}


class EquipmentCBMEnvironment(gym.Env):
    """
    2x2 Markov CBM Environment for Equipment Maintenance
    
    State: [condition, normalized_temperature]
    - condition: 0=normal, 1=anomalous
    - normalized_temperature: 0.0~1.0 scaled from actual temperature
    
    Action: 0=DoNothing, 1=Repair, 2=Replace
    
    Reward: Risk suppression + Cost minimization
    """
    
    metadata = {'render_modes': ['human', 'ansi'], 'render_fps': 1}
    
    def __init__(
        self,
        transition_matrix: Optional[np.ndarray] = None,
        temperature_range: Tuple[float, float] = (0.0, 150.0),
        normal_temp_range: Tuple[float, float] = (20.0, 100.0),
        horizon: int = 100,
        gamma: float = 0.95,
        risk_weight: float = 1.0,
        cost_lambda: float = 0.15,
        scenario: Optional[str] = None,
        equipment_age: float = 0.0,
        aging_factor: float = 0.01,  # å¹´é–“ç•°å¸¸ç¢ºç‡ã®å¢åŠ ç‡
        max_equipment_age: float = 50.0,  # æœ€å¤§è¨­å‚™å¹´æ•°
        seed: Optional[int] = None,
        render_mode: Optional[str] = None
    ):
        """
        Args:
            transition_matrix: DoNothingæ™‚ã®2x2é·ç§»è¡Œåˆ— [[p_nn, p_na], [p_an, p_aa]]
            temperature_range: æ¸©åº¦ã®ç‰©ç†çš„ç¯„å›² (min, max)
            normal_temp_range: æ­£å¸¸ç¯„å›²ã®æ¸©åº¦ (min, max)
            horizon: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰é•·
            gamma: å‰²å¼•ç‡
            risk_weight: ãƒªã‚¹ã‚¯ãƒšãƒŠãƒ«ãƒ†ã‚£ã®é‡ã¿ (å¤§ãã„ã»ã©å®‰å…¨é‡è¦–)
            cost_lambda: ã‚³ã‚¹ãƒˆãƒšãƒŠãƒ«ãƒ†ã‚£ã®é‡ã¿ (å¤§ãã„ã»ã©ã‚³ã‚¹ãƒˆé‡è¦–)
            scenario: ãƒ—ãƒªã‚»ãƒƒãƒˆã‚·ãƒŠãƒªã‚ª ('safety_first', 'cost_efficient', 'balanced')
            seed: ä¹±æ•°ã‚·ãƒ¼ãƒ‰
            render_mode: ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰
        """
        super().__init__()
        
        # Apply scenario preset if specified
        if scenario is not None:
            if scenario not in MAINTENANCE_SCENARIOS:
                raise ValueError(f"Unknown scenario: {scenario}. Choose from {list(MAINTENANCE_SCENARIOS.keys())}")
            preset = MAINTENANCE_SCENARIOS[scenario]
            risk_weight = preset['risk_weight']
            cost_lambda = preset['cost_lambda']
            print(f"\nğŸ“‹ Maintenance Scenario: {scenario}")
            print(f"   {preset['description']}")
            print(f"   Risk Weight: {risk_weight}, Cost Lambda: {cost_lambda}\n")
        
        self.render_mode = render_mode
        self.horizon = horizon
        self.gamma = gamma
        self.risk_weight = risk_weight
        self.cost_lambda = cost_lambda
        self.scenario = scenario
        
        # Temperature settings
        self.temp_min, self.temp_max = temperature_range
        self.normal_temp_min, self.normal_temp_max = normal_temp_range
        
        # Equipment aging settings
        self.initial_equipment_age = equipment_age
        self.aging_factor = aging_factor  # å¹´é–“ç•°å¸¸ç¢ºç‡ã®å¢åŠ ç‡
        self.max_equipment_age = max_equipment_age
        self.equipment_age = equipment_age  # ç¾åœ¨ã®è¨­å‚™å¹´æ•°
        
        # Transition matrix
        if transition_matrix is not None:
            # Use provided transition matrix for DoNothing
            assert transition_matrix.shape == (2, 2), "Transition matrix must be 2x2"
            self.transitions = DEFAULT_TRANSITIONS.copy()
            self.transitions[0] = transition_matrix.astype(np.float32)
        else:
            self.transitions = DEFAULT_TRANSITIONS.copy()
        
        # Action and observation spaces
        self.action_space = spaces.Discrete(3)  # 0=DoNothing, 1=Repair, 2=Replace
        
        # Observation: [condition (0 or 1), normalized_temperature (0~1), normalized_age (0~1)]
        self.observation_space = spaces.Box(
            low=np.array([0.0, 0.0, 0.0], dtype=np.float32),
            high=np.array([1.0, 1.0, 1.0], dtype=np.float32),
            dtype=np.float32
        )
        
        # Episode tracking
        self.current_step = 0
        self.current_condition = 0  # 0=normal
        self.current_temperature = 0.0
        
        # Random seed
        if seed is not None:
            self.np_random = np.random.RandomState(seed)
        else:
            self.np_random = np.random.RandomState()
    
    def _normalize_temperature(self, temp: float) -> float:
        """æ¸©åº¦ã‚’0~1ã«ã‚¹ã‚±ãƒ¼ãƒ«"""
        return (temp - self.temp_min) / (self.temp_max - self.temp_min)
    
    def _denormalize_temperature(self, norm_temp: float) -> float:
        """0~1ã‚¹ã‚±ãƒ¼ãƒ«ã‚’å®Ÿæ¸©åº¦ã«æˆ»ã™"""
        return norm_temp * (self.temp_max - self.temp_min) + self.temp_min
    
    def _sample_temperature(self, condition: int) -> float:
        """çŠ¶æ…‹ã«å¿œã˜ãŸæ¸©åº¦ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""
        if condition == 0:  # Normal
            # æ­£å¸¸ç¯„å›²å†…ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            temp = self.np_random.uniform(self.normal_temp_min, self.normal_temp_max)
        else:  # Anomalous
            # æ­£å¸¸ç¯„å›²å¤–ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            if self.np_random.rand() < 0.5:
                # ä¸‹é™ä»¥ä¸‹
                temp = self.np_random.uniform(self.temp_min, self.normal_temp_min)
            else:
                # ä¸Šé™ä»¥ä¸Š
                temp = self.np_random.uniform(self.normal_temp_max, self.temp_max)
        return temp
    
    def _get_age_adjusted_transition(self, base_transition: np.ndarray) -> np.ndarray:
        """è¨­å‚™å¹´æ•°ã‚’è€ƒæ…®ã—ãŸçŠ¶æ…‹é·ç§»è¡Œåˆ—ã‚’å–å¾—
        
        Args:
            base_transition: åŸºæœ¬ã®é·ç§»è¡Œåˆ—
        
        Returns:
            è€æœ½åŒ–ã‚’è€ƒæ…®ã—ãŸé·ç§»è¡Œåˆ—
        """
        # è€æœ½åŒ–ã«ã‚ˆã‚‹ç•°å¸¸ã¸ã®é·ç§»ç¢ºç‡å¢—åŠ 
        aging_effect = self.equipment_age * self.aging_factor
        adjusted = base_transition.copy()
        
        # NormalçŠ¶æ…‹ã‹ã‚‰Anomalousã¸ã®é·ç§»ç¢ºç‡ã‚’å¢—åŠ 
        if adjusted[0, 1] + aging_effect < 1.0:
            adjusted[0, 1] += aging_effect
            adjusted[0, 0] = 1.0 - adjusted[0, 1]
        else:
            # ä¸Šé™ã«é”ã—ãŸå ´åˆ
            adjusted[0, 1] = 0.99
            adjusted[0, 0] = 0.01
            
        # AnomalousçŠ¶æ…‹ã‹ã‚‰Normalã¸ã®å›å¾©ç¢ºç‡ã‚’è‹¥å¹²æ¸›å°‘
        recovery_penalty = aging_effect * 0.5  # è»½å¾®ãªå½±éŸ¿
        if adjusted[1, 0] - recovery_penalty > 0.0:
            adjusted[1, 0] -= recovery_penalty
            adjusted[1, 1] = 1.0 - adjusted[1, 0]
        
        return adjusted
    
    def reset(
        self,
        seed: Optional[int] = None,
        options: Optional[Dict] = None
    ) -> Tuple[np.ndarray, Dict]:
        """ç’°å¢ƒã‚’ãƒªã‚»ãƒƒãƒˆ"""
        if seed is not None:
            self.np_random = np.random.RandomState(seed)
        
        # åˆæœŸçŠ¶æ…‹: Normal
        self.current_step = 0
        self.current_condition = 0
        self.current_temperature = self._sample_temperature(0)
        self.equipment_age = self.initial_equipment_age  # è¨­å‚™å¹´æ•°ã‚’ãƒªã‚»ãƒƒãƒˆ
        
        obs = self._get_observation()
        info = {
            'condition': STATE_NAMES[self.current_condition],
            'temperature': self.current_temperature,
            'equipment_age': self.equipment_age
        }
        
        return obs, info
    
    def _get_observation(self) -> np.ndarray:
        """è¦³æ¸¬å€¤ã‚’å–å¾—"""
        norm_temp = self._normalize_temperature(self.current_temperature)
        norm_age = min(self.equipment_age / self.max_equipment_age, 1.0)  # 0~1ã«æ­£è¦åŒ–
        return np.array([float(self.current_condition), norm_temp, norm_age], dtype=np.float32)
    
    def step(self, action: int) -> Tuple[np.ndarray, float, bool, bool, Dict]:
        """ç’°å¢ƒã‚’1ã‚¹ãƒ†ãƒƒãƒ—é€²ã‚ã‚‹
        
        Args:
            action: 0=DoNothing, 1=Repair, 2=Replace
        
        Returns:
            observation, reward, terminated, truncated, info
        """
        assert self.action_space.contains(action), f"Invalid action: {action}"
        
        # Current state
        old_condition = self.current_condition
        
        # --- Risk Reward Component ---
        # Normal: +1, Anomalous: -10 (scaled by risk_weight)
        if old_condition == 0:
            risk_reward = 1.0 * self.risk_weight
        else:
            risk_reward = -10.0 * self.risk_weight
        
        # --- Cost Component ---
        action_cost = ACTION_COSTS[action] * self.cost_lambda
        cost_reward = -action_cost
        
        # --- Total Reward ---
        reward = risk_reward + cost_reward
        
        # --- State Transition ---
        if action == 0:  # DoNothing
            # Use age-adjusted transition matrix
            base_trans = self.transitions[0]
            age_adjusted_trans = self._get_age_adjusted_transition(base_trans)
            trans_probs = age_adjusted_trans[old_condition]
            new_condition = self.np_random.choice([0, 1], p=trans_probs)
        
        elif action == 1:  # Repair
            # Reset to normal with high probability (less aging effect)
            base_trans = self.transitions[1]
            age_adjusted_trans = self._get_age_adjusted_transition(base_trans)
            trans_probs = age_adjusted_trans[old_condition]
            new_condition = self.np_random.choice([0, 1], p=trans_probs)
        
        elif action == 2:  # Replace
            # Reset to normal with very high probability and reset equipment age
            base_trans = self.transitions[2]
            trans_probs = base_trans[old_condition]  # äº¤æ›æ™‚ã¯è€æœ½åŒ–ãƒªã‚»ãƒƒãƒˆ
            new_condition = self.np_random.choice([0, 1], p=trans_probs)
            self.equipment_age = 0.0  # è¨­å‚™å¹´æ•°ã‚’ãƒªã‚»ãƒƒãƒˆ
        
        # Sample new temperature
        self.current_condition = new_condition
        self.current_temperature = self._sample_temperature(new_condition)
        
        # Update equipment age (except when replaced)
        if action != 2:  # Replaceä»¥å¤–ã¯å¹´æ•°ã‚’é€²ã‚ã‚‹
            self.equipment_age += (1.0 / self.horizon)  # 1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ = ç´„1å¹´ã¨ä»®å®š
        
        # Step increment
        self.current_step += 1
        
        # Episode termination
        terminated = False
        truncated = self.current_step >= self.horizon
        
        # Info
        info = {
            'action': ACTION_NAMES[action],
            'old_condition': STATE_NAMES[old_condition],
            'new_condition': STATE_NAMES[new_condition],
            'temperature': self.current_temperature,
            'equipment_age': self.equipment_age,
            'aging_factor': self.aging_factor,
            'risk_reward': risk_reward,
            'cost_reward': cost_reward,
            'total_reward': reward,
            'step': self.current_step
        }
        
        obs = self._get_observation()
        
        return obs, reward, terminated, truncated, info
    
    def render(self):
        """ç’°å¢ƒã®æç”»"""
        if self.render_mode == 'human' or self.render_mode == 'ansi':
            condition_str = STATE_NAMES[self.current_condition]
            temp_str = f"{self.current_temperature:.1f}Â°C"
            age_str = f"{self.equipment_age:.1f}å¹´"
            print(f"Step {self.current_step}: {condition_str}, Temp={temp_str}, Age={age_str}")


def test_environment():
    """ç’°å¢ƒã®å‹•ä½œãƒ†ã‚¹ãƒˆ"""
    print("="*60)
    print("ğŸ§ª Equipment CBM Environment Test")
    print("="*60)
    
    # ã‚µãƒ³ãƒ—ãƒ«é·ç§»è¡Œåˆ—ï¼ˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¨å®šã—ãŸã‚‚ã®ã‚’æƒ³å®šï¼‰
    transition_matrix = np.array([
        [0.96, 0.04],  # Normal â†’ [Normal, Anomalous]
        [0.15, 0.85],  # Anomalous â†’ [Normal, Anomalous]
    ], dtype=np.float32)
    
    env = EquipmentCBMEnvironment(
        transition_matrix=transition_matrix,
        temperature_range=(0.0, 150.0),
        normal_temp_range=(20.0, 100.0),
        horizon=20,
        seed=42,
        render_mode='human'
    )
    
    print("\nâœ… Environment created")
    print(f"  - Action space: {env.action_space}")
    print(f"  - Observation space: {env.observation_space}")
    print(f"  - Transition matrix:\n{transition_matrix}")
    
    # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å®Ÿè¡Œ
    obs, info = env.reset(seed=42)
    print(f"\nğŸ¬ Initial: condition={info['condition']}, temp={info['temperature']:.1f}Â°C")
    
    total_reward = 0.0
    actions_taken = []
    
    for step in range(20):
        # ãƒ©ãƒ³ãƒ€ãƒ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆå®Ÿéš›ã«ã¯DQNãŒé¸æŠï¼‰
        if env.current_condition == 1:  # Anomalousãªã‚‰ä¿®ç†
            action = env.action_space.sample()  # 1 or 2
            if action == 0:
                action = 1
        else:
            action = 0  # Normalãªã‚‰ä½•ã‚‚ã—ãªã„
        
        obs, reward, terminated, truncated, info = env.step(action)
        total_reward += reward
        actions_taken.append(info['action'])
        
        print(f"  Action: {info['action']:10s} | "
              f"{info['old_condition']} â†’ {info['new_condition']:10s} | "
              f"Reward: {reward:6.2f} | Temp: {info['temperature']:5.1f}Â°C")
        
        if terminated or truncated:
            break
    
    print(f"\nğŸ“Š Episode Summary:")
    print(f"  - Total steps: {env.current_step}")
    print(f"  - Total reward: {total_reward:.2f}")
    print(f"  - Actions: {dict((a, actions_taken.count(a)) for a in set(actions_taken))}")


if __name__ == "__main__":
    test_environment()
